{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N9K9250KsUo"
      },
      "source": [
        "# Теория вероятностей и математическая статистика\n",
        "## Метод максимального правдоподобия\n",
        "### Содержание\n",
        "\n",
        "0. [Введение: выборка](#par0)\n",
        "1. [Общая идея: что такое правдоподобие и функция правдоподобия](#par1)\n",
        "2. [Пример MLE для биномиального распределения](#par2)\n",
        "3. [Пример MLE для распределения Пуассона](#par3)\n",
        "4. [Пример MLE для экспоненциального распределения](#par4)\n",
        "5. [Пример MLE для нормального распределения](#par5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02cFEFjDKsUq"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy matplotlib seaborn scipy -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lchtuBDeKsUr"
      },
      "source": [
        "### 0. Введение: выборка и предпосылки для понимания MLE <a name=\"par0\"></a>\n",
        "\n",
        "В этом конспекте-практикуме мы подробно поговорим об одном из самых популярных в статистике методе для оценивания неизвестного параметра — *методе максимального правдоподобия* (ММП / maximum likelihood estimation / MLE). Но, прежде всего, нужно освежить некоторые базовые понятия, имеющие прямое отношение к этому занятию: в частности, выборку и её статистические свойства.\n",
        "\n",
        "#### Выборка\n",
        "\n",
        "Хотя мы неоднократно употребляли термин **«выборка»** на занятиях, стоит четко концептуализировать это понятие, поскольку оно потребуется нам дальше.\n",
        "\n",
        "- **Определение**: *выборка* — совокупность независимых и одинаково распределенных (independent and identically distributed / $i.i.d.$) случайных величин. При этом важно, что речь идет не только об одинаковом характере распределения сл. в., но и об одинаковых параметрах этого распределения (например, $N(0, 1)$ — среднее значение 0 и дисперсия 1 у нормального распределения).\n",
        "- **Обозначение**: выборка обычно обозначается как $ X = (x_1, x_2, ..., x_n) $, где каждый $ x_i $ — это отдельное наблюдение, а $ n $ — размер выборки.\n",
        "\n",
        "##### Ключевые концепции, связанные с выборками:\n",
        "\n",
        "1. **Случайная выборка**: процесс формирования выборки таким образом, чтобы каждый элемент генеральной совокупности (ГС / population) имел равные шансы попасть в нее. Это критически важно для репрезентативности выборки.\n",
        "2. **Размер выборки ($ n $)**: количество наблюдений в выборке. Оно играет значительную роль в статистическом выводе (statistical inference), влияя на основные свойства оценок (о них ниже).\n",
        "3. **Параметр против оценки**: параметр ГС — это значение, описывающее характеристику всей популяции (и мы никогда не можем определить его в явном виде), в то время как оценка — это значение, описывающее неизвестный параметр распределения случайной величины, которое мы находим исходя из выборки.\n",
        "Например, параметр «среднее значение»: $ \\mu $ и выборочное среднее значение (оценка): $ \\bar{x} $. По значению второго мы делаем предположение о первом. Часто параметр, в общем случае, обозначают как $ \\theta $, а оценку — как $ \\hat{\\theta} $.\n",
        "4. **Распределение выборки**: важно понимать распределение вероятностей случайной величины, из которой к нам приходит выборка. Мы уже изучили многие из них: нормальное, биномиальное, Пуассона, экспоненциальное и т.д. Каждое из этих распределений имеет свои параметры:\n",
        "    * $ n $ (число независимых случайных экспериментов) и $ p $ (вероятность «успеха» в каждом из них) у биномиального распределения,\n",
        "    * $ \\lambda $ (среднее количество событий за фиксированный промежуток времени) у распределения Пуассона,\n",
        "    * $ \\lambda $ (интенсивность или частота) у экспоненциального распределения,\n",
        "    * $ \\mu $ и $ \\sigma^2 $ (среднее и дисперсия) у нормального распределения,\n",
        "    * и т.д.\n",
        "    \n",
        "Однако в реальных данных мы не всегда можем определить конкретное распределение вероятностей, из которого к нам пришла выборка.\n",
        "\n",
        "#### Статистический вывод (statistical inference)\n",
        "\n",
        "Статистический вывод — это фундаментальный аспект статистики, который включает в себя выводы о генеральной совокупности на основе выборки, взятой из этой ГС. Он охватывает различные методы и техники, используемые для оценки параметров, проверки гипотез и прогнозирования. Основная идея статистического вывода заключается в том, чтобы делать выводы о свойствах неизвестной популяции через меньшую, наблюдаемую выборку.\n",
        "\n",
        "К примеру, в политической науке статистический вывод может использоваться для:\n",
        "- анализа опросных данных (например, предпочтений избирателей, рейтингов одобрения и поддержки деятельности политиков),\n",
        "- изучения эффектов реформ (например, влияния нового закона на общественное мнение),\n",
        "- исследования взаимосвязей между переменными (например, демократические институты и экономическое развитие),\n",
        "- прогнозирования результатов выборов.\n",
        "\n",
        "Статистический вывод можно условно разделить на две большие части:\n",
        "1. Оценивание параметров.\n",
        "2. Проверка гипотез.\n",
        "\n",
        "Частично мы уже затрагивали оба пункта, но сейчас мы поговорим именно про оценивание параметров, которое тоже можно разделить на две части:\n",
        "1. Точечное оценивание.\n",
        "2. Интервальное.\n",
        "\n",
        "На 1 курсе Вы познакомились с интервальным оцениванием, когда строили доверительные интервалы для среднего значения и выборочной доли. Сейчас же мы подробнее остановимся на **точечном оценивании**, одним из самых популярных представителей которого и является метод максимального правдоподобия (однако стоит отметить, что на основе оценок MLE тоже можно построить доверительные интервалы)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5IbwjCvKsUs"
      },
      "source": [
        "### 1. Общая идея: что такое правдоподобие и функция правдоподобия <a name=\"par1\"></a>\n",
        "\n",
        "#### Правдоподобие\n",
        "\n",
        "- **Определение**: правдоподобие — это концепт, используемый для измерения вероятности наблюдения данной выборки при различных значениях параметров.\n",
        "- **Формальное определение**: для имеющейся выборки из наблюдаемых данных $ X = (x_1, x_2, ..., x_n) $ правдоподобие (*likelihood*) определяется как вероятность получения данной конкретной выборки (при заданном значении параметра $ \\theta $): $ L(x_1, x_2, ..., x_n) = P(X) = P(X = x_1 \\cap X = x_2 \\cap ... \\cap X = x_n) = P(X = x_1) \\cdot P(X = x_2) \\cdot ... \\cdot P(X = x_n)$. Также правдоподобие можно записать как $ P(X | \\theta) = P(\\{data\\} | \\theta)$.\n",
        "- **Интерпретация**: дословно, правдоподобие можно трактовать как ответ на следующий вопрос:\n",
        "    1. «Если бы определенное значение параметра было верным, насколько вероятно было бы наблюдать имеющиеся у нас данные?»\n",
        "    2. «Какая вероятность получить ту выборку, которую мы получили?»\n",
        "\n",
        "К примеру, у нас есть «нечестная мотетка»: мы предполагаем, что вероятность выпадения «орла» составляет 0.8: $ \\theta = 0.8$. Какое правдоподобие будет у следующей выборки: $\\ \\{ р, р, р, о, р \\} $? Ответ: $ 0.2^4 \\cdot 0.8 \\approx 0.001 $. А у такой:$\\ \\{ о, о, о, о, о \\} $? Ответ: $ 0.8^5 \\approx 0.328 $ — гораздо более вероятно.\n",
        "\n",
        "#### Функция правдоподобия\n",
        "\n",
        "- **Определение**: функция правдоподобия — более формальное представление концепции правдоподобия. Данные из выборки подставляются в функцию правдоподобия для нахождения значений параметров, которые максимизируют эту функцию. По сути, мы используем данные из выборки для наилучшей возможной оценки параметров ГС, используя функцию правдоподобия.\n",
        "- **Формальное определение**: функция правдоподобия является совместным распределение выборки из параметрического распределения, которое можно рассматривать как функцию параметра $ \\theta $: $ L(\\theta) = P(\\theta | X) = (\\theta | x_1, x_2, ..., x_n) = P(\\theta | \\{data\\}) $. То есть, наоборот, мы хотим получить вероятность получения значения параметра $ \\theta $ при условии выборки (данных).\n",
        "- **Непрерывный случай**: для непрерывных распределений $ L(\\theta) = f(\\theta | x_1, x_2, ..., x_n) $, где $ f $ — совместная функция плотности вероятности.\n",
        "- **Дискретный случай**: для дискретных распределений $ L(\\theta) = P(\\theta | x_1, x_2, ..., x_n) $, где $ P $ — совместная функция вероятности.\n",
        "\n",
        "Неформально можно сказать, что мы используем правдоподобие, чтобы получить вероятность выборки при известных параметрах, а функцию правдоподобия — чтобы оценить вероятность неизвестных параметров при известных результатах (выборке).\n",
        "\n",
        "Если более четко проследить разницу между ними, то получится, что:\n",
        "- правдоподобие — это всегда числовое значение для данного параметра, которое можно посчитать с учетом выборки, а функция правдоподобия — функция, которая отражает эту взаимосвязь для всех возможных значений параметров,\n",
        "- правдоподобие говорит нам о том, насколько вероятно конкретное значение параметра для наблюдаемых данных. В отличие от этого, функция правдоподобия используется как инструмент для оценки, являясь основой для оценки правдоподобия различных значений параметров.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### Нахождение оценки параметра с использованием MLE\n",
        "\n",
        "- **Предположения**: для применения MLE необходимо иметь представление о выборке и распределении случайной величины, из которой она пришла.\n",
        "\n",
        "Процесс нахождения оценки максимального правдоподобия параметра $ \\theta $ обычно включает следующие шаги:\n",
        "\n",
        "1. **Построение функции правдоподобия**: на основе выбранного распределения и наблюдаемых данных нужно выписать функцию правдоподобия $ L(\\theta | X) $.\n",
        "\n",
        "2. **Логарифм функции правдоподобия (логарифмическое правдоподобие)**: для упрощения расчетов обычно от функции правдоподобия берут натуральный логарифм, получая функцию логарифмического правдоподобия $ \\ln(L(\\theta | X)) $.\n",
        "    * Это делается для того, что бы упростить задачу нахождения параметра, который максимизирует функцию правдоподобия (т.е. точку эстремума или значение, при котором функция правдоподобия будет максимальной). Поскольку логарифм является монотонно возрастающей функцией, максимизация логарифма функции правдоподобия эквивалентна максимизации самой функции правдоподобия.\n",
        "    * При этом, логарифм произведения является суммой логарифмов, что упрощает дифференцирование и позволяет легко избавиться от ненужных констант.\n",
        "3. **Дифференцирование**: берем частную производную функции логарифмического правдоподобия по $ \\theta $, чтобы получить $ \\frac{d\\ln(L(\\theta | X))}{d\\theta} $.\n",
        "\n",
        "4. **Нахождение точки экстремума**: приравниваем производную к нулю и решаем уравнение относительно $ \\theta $. Этот шаг включает нахождение значения $ \\theta $, при котором функция логарифмического правдоподобия (а следовательно, и сама функция правдоподобия) достигает своего максимума. Таким образом, решение уравнения дает нам MLE-оценку $ \\hat{\\theta}^{MLE} $ параметра $ \\theta $, указывая на точку экстремума, в которой функция правдоподобия является максимальной.\n",
        " Из этой логики берется темин «максимальное правдоподобие».\n",
        "\n",
        "Важно отметить, что на практике (в частности, в статистических пакетах и языках программирования) часто используются численные методы и алгоритмы оптимизации для нахождения MLE, поскольку аналитическое решение зачастую очень трудоемко.\n",
        "\n",
        "#### Свойства MLE-оценок\n",
        "\n",
        "Стоит отметить *свойства* MLE-оценок в целом:\n",
        "\n",
        "- **Асимптотическая несмещенность**: с увеличением размера выборки математическое ожидание оценки стремится к оцениваемому параметру, или $ \\lim_{n \\to \\infty} E(\\hat{\\theta}_n) = \\theta $. Это свойство указывает на то, что при больших объемах выборки оценка становится несмещенной.\n",
        "\n",
        "- **Состоятельность**: оценка сходится по вероятности к истинному значению параметра по мере увеличения размера выборки. Это означает, что с увеличением объема выборки оценка становится более точной, или, формально, для любого $ \\epsilon > 0 : \\ \\lim_{n \\to \\infty} P(|\\hat{\\theta}_n - \\theta| < \\epsilon) = 1 $.\n",
        "\n",
        "- **Асимптотическая эффективность**: с увеличением размера выборки дисперсия MLE-оценок стремится к минимально возможной среди всех оценок. Это минимальное значение дисперсии оценок определяется через нижнюю границу, известную как неравенство (граница) Крамера-Рао, которая устанавливает теоретический минимум дисперсии, который может иметь несмещенная оценка параметра на основе данной выборки. Для MLE-оценки $ \\hat{\\theta} $ это означает, что при больших объемах выборки ее дисперсия $ Var(\\hat{\\theta}) $ приближается к этому минимуму, обеспечивая наивысшую точность оценки параметра среди всех возможных несмещенных оценок. Например, между двумя несмещенными оценками $ \\hat{\\theta}_1 $ и $ \\hat{\\theta}_2 $, $ \\hat{\\theta}_1 $ более эффективна, чем $ \\hat{\\theta}_2 $, если $Var(\\hat{\\theta}_1) < Var(\\hat{\\theta}_2) $\n",
        "\n",
        "- **Чувствительность к выбросам (неустойчивость)**: подобно многим другим оценкам, MLE может быть чувствительной к выбросам в данных, что может повлиять на ее свойства, особенно на малых выборках. В таком случае MLE может дать смещенный результат.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ULTv05eKsUu"
      },
      "source": [
        "### 2. Пример MLE для биномиального распределения <a name=\"par2\"></a>\n",
        "\n",
        "Рассмотрим два примера для биномиального распределения: найдем оценку параметра $p$ (вероятность «успеха») с помощью MLE, а также оценим вероятность получения выборок при известном параметре $p$ с помощью функции правдоподобия.\n",
        "\n",
        "#### Поиск оценки параметра $p$\n",
        "\n",
        "Представим, что был проведен референдум для оценки степени общественной поддержки некоторой политической реформы.\n",
        "Мы имеем случайную выборку из 10 человек, которых опросили, поддерживают ли они реформу.\n",
        "\n",
        "Предположим, что ответы следующие (1 означает поддержку, а 0 — отсутствие поддержки):\n",
        "$$\n",
        "X = \\{1, 0, 1, 1, 0, 1, 1, 1, 0, 1\\}\n",
        "$$\n",
        "\n",
        "В этой выборке $ n = 10 $ (общее количество наблюдений) и количество «успехов» составляет $ x = 7 $.\n",
        "\n",
        "Биномиальное распределение подходит нам, поскольку оно описывает количество успехов в фиксированном количестве независимых испытаний Бернулли.\n",
        "\n",
        "#### Функция правдоподобия для биномиального распределения\n",
        "\n",
        "Функция правдоподобия для биномиального распределения, учитывая $ n $ испытаний и $ x $ успехов, имеет вид:\n",
        "$$\n",
        "L(p | X) = P(X = x | p) = C_n^x \\ p^x (1 - p)^{n - x}\n",
        "$$\n",
        "\n",
        "Где:\n",
        "- $L(p | X)$ — вероятность наблюдения $ x $ успехов при вероятности успеха $ p $.\n",
        "- $C_n^x$ — биномиальный коэффициент.\n",
        "\n",
        "#### Maximum likelihood estimation\n",
        "\n",
        "Будем следовать алгоритму, который обсуждался выше, чтобы найти значение $ \\theta $ (в нашем случае это  $ p $), которое максимизирует $ L(\\theta | X) $. В начале найдем решение в общем виде, а затем подставим конкретные значения из условия.\n",
        "\n",
        "1. **Логарифмическая функция правдоподобия**: сначала мы берем натуральный логарифм функции правдоподобия, чтобы упростить расчеты:\n",
        "\n",
        "   $$\n",
        "   \\ln(L(p | X)) = \\ln C_n^x + x \\log p + (n - x) \\log (1 - p)\n",
        "   $$\n",
        "\n",
        "2. **Дифференцирование**: затем мы дифференцируем $ \\ln(L(p | X)) $ по $ p $:\n",
        "\n",
        "   $$\n",
        "   \\dfrac{d \\ln(L(p | X))}{dp} = \\dfrac{x}{p} - \\dfrac{n - x}{1 - p}\n",
        "   $$\n",
        "\n",
        "   Заметим, что логарифмирование позволило нам избавиться от константы $\\ln C_n^x$.\n",
        "\n",
        "3. **Приравнивание производной к нулю**: чтобы найти максимум, приравниваем производную к нулю и решаем относительно $ p $:\n",
        "\n",
        "   $$\n",
        "   \\frac{x}{p} - \\frac{n - x}{1 - p} = 0\n",
        "   $$\n",
        "\n",
        "   $$\n",
        "   \\Rightarrow x(1 - p) = p(n - x)\n",
        "   $$\n",
        "\n",
        "   $$\n",
        "   \\Rightarrow xp - xp^2 = np - xp\n",
        "   $$\n",
        "\n",
        "   $$\n",
        "   \\Rightarrow xp^2 - (x + n)p + x = 0\n",
        "   $$\n",
        "\n",
        "4. **Решение для $ p $**: это квадратное уравнение относительно $ p $. Оно сокращается до доли успехов, что довольно очевидно:\n",
        "\n",
        "   $$\n",
        "   \\Rightarrow \\hat{p}^{MLE} = \\frac{x}{n}\n",
        "   $$\n",
        "\n",
        "   Таким образом, доля успехов $ \\frac{x}{n} $ является MLE-оценкой для вероятности «успеха» $p$ из биномиального распределения.\n",
        "\n",
        "#### MLE для нашей выборки\n",
        "\n",
        "Теперь мы можем легко получить оценку $\\hat{p}^{MLE}$ для нашей выборки: $ x = 7 $ и $ n = 10 $:\n",
        "\n",
        "$$\n",
        "\\hat{p}^{MLE} = \\frac{7}{10} = 0.7\n",
        "$$\n",
        "\n",
        "Таким образом, оценка вероятности того, что случайный индивид поддержит реформу в нашем гипотетическом референдуме, полученная с помощью MLE на основе нашей выборки, составляет 0.7.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un40xMTNKsUu"
      },
      "source": [
        "Рассмотрим другой пример: нам дана выборка из биномиального распределения с параметрами $n = 10$, $p = 0.8$, состоящая из следующих наблюдений: $\\{5, 7, 9\\}$.\n",
        "\n",
        "1. Чему равно правдоподобие этой выборки (какова вероятность получить эту выборку)?\n",
        "2. Получим посредством метода максимального правдоподобия оценку параметра $p$ — вероятности успеха.\n",
        "\n",
        "**Чему равно правдоподобие этой выборки (какова вероятность получить эту выборку)?**\n",
        "\n",
        "Чтобы ответить на этот вопрос и найти $L(data | p)$, нам нужно посчитать вероятность получения каждого из элементов выборки ($ P(X = x_i) $) и перемножить их, поскольку эти события независимы. То есть:\n",
        "$$\n",
        "L(data | p) = P(X = 5) \\cdot P(X = 7) \\cdot P(X = 9)\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(X = 5) = \\dfrac{10!}{5! \\cdot 5!} \\cdot 0.8^5 \\cdot 0.2^5 \\approx 0.026\n",
        "$$\n",
        "$$\n",
        "P(X = 7) = \\dfrac{10!}{7! \\cdot 3!} \\cdot 0.8^7 \\cdot 0.2^3 \\approx 0.201\n",
        "$$\n",
        "$$\n",
        "P(X = 9) = \\dfrac{10!}{9! \\cdot 1!} \\cdot 0.8^9 \\cdot 0.2^1 \\approx 0.268\n",
        "$$\n",
        "\n",
        "Тогда:\n",
        "$$\n",
        "L(data | p) = 0.026 \\cdot 0.201 \\cdot 0.268 \\approx 0.0014\n",
        "$$\n",
        "\n",
        "Мы нашли вероятность получить выборку $\\{5, 7, 9\\}$ из биномиального распределения с параметрами $n = 10$, $p = 0.8$ !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3FM2vwXKsUx"
      },
      "source": [
        "**Получим посредством метода максимального правдоподобия оценку параметра $p$ — вероятности успеха.**\n",
        "\n",
        "Выведем функцию правдоподобия:\n",
        "$$\n",
        "L(p | data) = ( C_{10}^5 \\ p^5 (1 - p)^{5} ) \\cdot ( C_{10}^7 \\ p^7 (1 - p)^{3} ) \\cdot ( C_{10}^9 \\ p^9 (1 - p)^{1} ) = p^{21} \\cdot (1 - p)^{9} \\cdot C_{10}^5 \\cdot C_{10}^7 \\cdot C_{10}^9\n",
        "$$\n",
        "Прологарифмируем ее, чтобы перейти к сумме для удобства дифференцирования:\n",
        "$$\n",
        "\\ln(L(p | data)) = \\ln(p^{21}) + \\ln( (1-p)^9 ) + \\ln(const) + \\ln(const) + \\ln(const)\n",
        "$$\n",
        "Обозначим биномиальные коэффициенты как $const$, поскольку они не важны нам для максимизации функции.\n",
        "\n",
        "Далее возьмем частную производную по параметру $p$ от логарифмической функции правдоподобия:\n",
        "$$\n",
        "\\dfrac{d \\ln(L(p | X))}{dp} = (21 \\ln p + 9 \\ln (1 - p))' = \\dfrac{21}{p} + \\left(-\\dfrac{9}{1 - p}\\right)\n",
        "$$\n",
        "\n",
        "Приравниванием производную к нулю и решим уравнение для $ p $:\n",
        "$$\n",
        "\\dfrac{d \\ln(L(p | X))}{dp} = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Rightarrow \\dfrac{21}{p} + \\left(-\\dfrac{9}{1 - p}\\right) = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Rightarrow \\dfrac{21}{p} = \\dfrac{9}{1 - p}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Rightarrow 9 p = 21 (1 - p)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Rightarrow 30 p = 21\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Rightarrow \\hat{p}^{MLE} = 0.7\n",
        "$$\n",
        "\n",
        "Мы нашли MLE-оценку параметра $p$! Можно заметить, что она равна среднему арифметическому из $\\{0.5, 0.7, 0.9\\}$ — долей успехов из нашей выборки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpWOsWwIKsUy"
      },
      "source": [
        "#### Практика в Python\n",
        "\n",
        "Попробуем решить те же задачи для биномиального распределения с использованием Python. Поскольку мы будем использовать язык программирования, а не аналитическое решение, попробуем решить задачу с помощью логарифмирования функции правдоподобия и без."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMbY3CUqKsUz"
      },
      "source": [
        "**Поиск оценки параметра $p$ для выборки $X = \\{1, 0, 1, 1, 0, 1, 1, 1, 0, 1\\}$**\n",
        "\n",
        "Решим задачу про референдум. Будем использовать для этого:\n",
        "- объект `binom` из модуля `scipy.stats` ([документация](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html))\n",
        "- и функцию `minimize_scalar` из модуля `scipy.optimize` ([документация](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize_scalar.html))\n",
        "\n",
        "Обратите внимание, что из-за особенности реализации библиотеки `scipy` технически мы будем минимизировать функцию правдоподобия, и для этого нам придется взять ее со знаком «минус», чтобы получить правильный результат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nd99MpcKsU0",
        "outputId": "af122eac-b6a2-4d8b-8759-82139628ddbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLE-оценка для параметра p: 0.699999913744543 (без логарифмирования функции правдоподобия)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import binom\n",
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "# Пример: MLE для биномиального распределения\n",
        "# Выборка:\n",
        "x = [1, 0, 1, 1, 0, 1, 1, 1, 0, 1]\n",
        "\n",
        "# Число успехов\n",
        "votes_received = sum(x)\n",
        "# Размер выборки\n",
        "total_votes = len(x)\n",
        "\n",
        "# Функция правдоподобия для биномиального распределения\n",
        "def binom_likelihood(p):\n",
        "    # Обратите внимание, что мы берем отрицательное значение функции правдоподобия,\n",
        "    # поскольку на следующем шаге мы будем минимизировать ее (а не максимизировать)\n",
        "    return -binom.pmf(votes_received, total_votes, p)\n",
        "\n",
        "# Найдем MLE для p\n",
        "# method='bounded', поскольку мы знаем, что параметр p лежит в границах [0, 1]\n",
        "result = minimize_scalar(binom_likelihood, bounds=(0, 1), method='bounded')\n",
        "\n",
        "# Результат:\n",
        "mle_p = result.x\n",
        "\n",
        "print(f'MLE-оценка для параметра p: {mle_p} (без логарифмирования функции правдоподобия)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJFnC_U8KsU1"
      },
      "source": [
        "Получили практически точную MLE-оценку по сравнению с аналитическим решением! Обратите внимание, что в этом случае мы не использовали логарифмирование функции правдоподобия, а брали результат `binom.pmf` напрямую (`binom.pmf` = $ P(X = x) $)\n",
        "\n",
        "Теперь найдем оценку, используя логарифмирование:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PyPsD3QKsU1",
        "outputId": "022ee1a6-b50b-4ec2-bc37-b93c0da0c0ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLE-оценка для параметра p: 0.7000003717368305 (с логарифмированием функции правдоподобия)\n"
          ]
        }
      ],
      "source": [
        "# Логарифмированная функция правдоподобия для биномиального распределения\n",
        "def binom_log_likelihood(p):\n",
        "    # Обратите внимание, что мы берем отрицательное значение функции правдоподобия,\n",
        "    # поскольку на следующем шаге мы будем минимизировать ее (а не максимизировать)\n",
        "    return -np.log(binom.pmf(votes_received, total_votes, p))\n",
        "\n",
        "# Найдем MLE для p\n",
        "# method='bounded', поскольку мы знаем, что параметр p лежит в границах [0, 1]\n",
        "result = minimize_scalar(binom_log_likelihood, bounds=(0, 1), method='bounded')\n",
        "\n",
        "# Результат:\n",
        "mle_p = result.x\n",
        "\n",
        "print(f'MLE-оценка для параметра p: {mle_p} (с логарифмированием функции правдоподобия)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbUMclA1KsU2"
      },
      "source": [
        "Погрешность немного больше, но, в целом, результат тоже близкий к аналитическому решению ($0.7$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAYXfUJ-KsU2"
      },
      "source": [
        "**Правдоподобие выборки $X = \\{5, 7, 9\\}$ и MLE-оценка параметра $p$**\n",
        "\n",
        "Далее решим вторую задачу, в которой нужно было найти правдоподобие выборки и получить оценку параметра $p$ для выборки из трех значений.\n",
        "\n",
        "Здесь будем использовать только вариант с логарифмированием и попробеум записать негативность лог-правдоподобия через другой синтаксис."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtmQVRnqKsU2",
        "outputId": "c80d5a88-6266-4924-ce03-0d8c59fc7c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Правдоподобие выборки X = [5, 7, 9]: 0.0014280436244197769\n",
            "\n",
            "MLE-оценка для параметра p: 0.7000003717368987 (с логарифмированием функции правдоподобия)\n"
          ]
        }
      ],
      "source": [
        "# Выборка из биномиального распределения\n",
        "sample = [5, 7, 9]\n",
        "# Число экспериментов\n",
        "n = 10\n",
        "# Вероятность успеха\n",
        "p_given = 0.8\n",
        "\n",
        "# Task 1: вычисление правдоподобия (likelihood) выборки\n",
        "# Правдоподобие - произведение вероятностей для каждого элемента выборки\n",
        "likelihood = np.prod(binom.pmf(sample, n, p_given))  # np.prod перемножает все элементы массива\n",
        "\n",
        "# Task 2: найдем MLE-оценку для параметра p\n",
        "# Определим функцию логарифмического правдоподобия\n",
        "def log_likelihood(p):\n",
        "    return np.sum(np.log(binom.pmf(sample, n, p)))  # помним про суммирование вместо перемножения\n",
        "\n",
        "# Найдием значение оценки параметра p, которое максимизирует логарифмическое правдоподобие\n",
        "# Используем lambda-функцию, чтобы передать в minimize_scalar отрицательное значение log_likelihood\n",
        "mle_result = minimize_scalar(lambda p: -log_likelihood(p), bounds=(0, 1), method='bounded')\n",
        "\n",
        "# Результат:\n",
        "mle_p = mle_result.x\n",
        "\n",
        "print(f'Правдоподобие выборки X = [5, 7, 9]: {likelihood}')\n",
        "print()\n",
        "print(f'MLE-оценка для параметра p: {mle_p} (с логарифмированием функции правдоподобия)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIjyQHPRKsU3"
      },
      "source": [
        "Получили правильный ответ! Запустив функцию `binom.pmf(sample, n, p)` для каждого из элемента выборки, можно посмотреть на конкретные значения вероятности для каждого элемента, как мы считали вручную:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqxQ-IIKKsU3",
        "outputId": "e254b8f0-c8d3-49c3-ad16-8ac45b2f9e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(X = 5) = 0.026424115199999963\n",
            "P(X = 7) = 0.20132659199999978\n",
            "P(X = 9) = 0.26843545599999996\n"
          ]
        }
      ],
      "source": [
        "for x_i in sample:\n",
        "    print(f'P(X = {x_i}) = {binom.pmf(x_i, 10, 0.8)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GWlgKOWKsU3"
      },
      "source": [
        "### 3. Пример MLE для распределения Пуассона <a name=\"par3\"></a>\n",
        "\n",
        "#### Вспоминаем распределение Пуассона\n",
        "\n",
        "Для начала вспомним суть **распределения Пуассона**.\n",
        "\n",
        "Распределение Пуассона — это дискретное вероятностное распределение, которое выражает вероятность наступления определенного количества событий (поэтому дискретное), происходящих в фиксированный интервал времени или пространства, при условии, что эти события происходят с известной постоянной средней скоростью и независимо друг от друга (т.е. от времени с момента последнего события).\n",
        "\n",
        "Параметр этого распределения: $\\lambda > 0$, средняя скорость, с которой происходят события (или $ n \\cdot p $, где $ n $ велико, а $ p $ — мало). Предполагается, что эта скорость постоянна.\n",
        "\n",
        "В целом же, **функция вероятности** для него выглядит так:\n",
        "$$\n",
        "P(X = x) = \\dfrac{\\lambda ^x}{x!} \\cdot e^{- \\lambda}\n",
        "$$,\n",
        "\n",
        "где $x$ — число событий, наступивших за период времени.\n",
        "\n",
        "Обычно распределение Пуассона используется для моделирования редких событий, где количество случаев за период времени невелико, потому что при больших значениях $\\lambda > 10$ распределение Пуассона аппроксимируется к нормальному распределению.\n",
        "\n",
        "К примеру, в политической науке его можно было бы использовать для оценки количества избирателей, приходящих на избирательный участок в течение заданного периода времени или для анализа упоминаний политиков в СМИ за определенный период.\n",
        "\n",
        "#### Нахождение оценки MLE для распределения Пуассона\n",
        "\n",
        "Попробуем вывести оценку параметра $\\lambda $ и решить следующую задачу:\n",
        "\n",
        "##### Задача\n",
        "\n",
        "В городе N проходят парламентские выборы.\n",
        "Для эффективной организации работы наблюдателей нам нужно понять частоту, с которой избиратели приходят на участок за один час, поскольку оплата за работу наблюдателей у нас почасовая.\n",
        "\n",
        "Нам нужно найти оценку среднего количества избирателей, посещающих избирательный участок в течение одного часа.\n",
        "Наблюдения проводились на одном из избирательных участков в городе N. Количество избирателей, приходящих за каждый час, записывалось за 12 часов работы избирательного участка.\n",
        "\n",
        "В результате мы получили следующую выборку:\n",
        "\n",
        "$$\n",
        "X = \\{2, 3, 2, 4, 1, 3, 3, 2, 4, 5, 1, 2\\}\n",
        "$$\n",
        "\n",
        "Каждый элемент выборки представляет количество избирателей, приходящих в каждый из 12 часов.\n",
        "\n",
        "Используя эти данные, найдите оценку среднего количества избирателей, приходящих на избирательный участок в час, с помощью MLE, используя распределение Пуассона.\n",
        "\n",
        "#### Решение\n",
        "\n",
        "Выведем оценку параметра $\\lambda $ распределения Пуассона с помощью MLE в общем виде.\n",
        "\n",
        "Мы помним как выглядит функция вероятности:\n",
        "$$\n",
        "P(X = x) = \\dfrac{\\lambda ^x}{x!} \\cdot e^{- \\lambda}\n",
        "$$\n",
        "\n",
        "**Функция правдоподобия**\n",
        "\n",
        "Для выборки $X$ функция правдоподобия распределения Пуассона:\n",
        "\n",
        "$$\n",
        "L(\\lambda | data) = ... \\cdot \\dfrac{\\lambda^x}{x!} e^{- \\lambda} \\cdot ... = e^{-n \\lambda} \\cdot \\lambda ^{\\sum x_i} \\cdot \\dfrac{1}{\\prod_{i=1}^{n} x_i !}\n",
        "$$\n",
        "\n",
        "Проанализируем, откуда мы взяли эти три множителя:\n",
        "1. $ e^{-n \\lambda} $: множитель $ \\ e^{- \\lambda}$ повторяется $n$ раз по числу элементов в выборке, поскольку $\\lambda$ — постоянная величина, а при умножении степени складываются.\n",
        "    * Например, $ e^{- \\lambda} \\cdot e^{- \\lambda} \\cdot e^{- \\lambda} = e^{- 3\\lambda}$\n",
        "2. $ \\lambda ^{\\sum x_i} $: множитель в виде числителя из дроби $ \\dfrac{\\lambda^x}{x!} $ также повторяется $n$ раз, однако каждый раз на месте $ \\lambda^x $ будет $\\lambda^{i\\text{-й элемент выборки}}$. Следовательно, поскольку $\\lambda$ — постоянная величина, можем просуммировать элементы нашей выборки.\n",
        "    * Например, для выборки $\\{3, 5, 7 \\}$ получим $ \\lambda^3 \\cdot \\lambda^5 \\cdot \\lambda^7 = \\lambda^{15} $\n",
        "3. $ \\dfrac{1}{\\prod_{i=1}^{n} x_i !} $: все просто — каждый раз подставляем в знаменатель из дроби $ \\dfrac{\\lambda^x}{x!} $ новый элемент выборки $x_i$, в результате получаем произведение из факториалов всех элементов нашей выборки (напомним, что символ $\\prod_{i=1}^{n}$ означает произведение элементов по аналогии с символом суммирования $\\sum_{i=1}^{n}$).\n",
        "    * Например, для выборки $\\{1, 2, 3 \\}$ получим $ 1! \\cdot 2! \\cdot 3! = 1 \\cdot 2 \\cdot 6 = 12$\n",
        "        * Напомним, что факториал числа $x!$ равен $ x \\cdot (x - 1) \\cdot ... \\cdot 1 $ или $ \\prod_{k=1}^{x} k $  \n",
        "\n",
        "**Логарифмическая функция правдоподобия**\n",
        "\n",
        "Далее прологарифмируем функцию правдоподобия\n",
        "\n",
        "$$\n",
        "\\ln(L(\\lambda | data)) = -n \\cdot \\lambda + \\sum x_i \\cdot \\ln(\\lambda) + \\ln \\left(\\prod_{i=1}^{n} x_i ! \\right)\n",
        "$$\n",
        "\n",
        "Помним, что последнее слагаемое для нас будет являться константой при дифференцировании.\n",
        "\n",
        "**Дифференцирование и максимизация**\n",
        "\n",
        "Как и до этого, для нахождения оценки MLE, мы дифференцируем логарифмическую функцию правдоподобия по параметру и приравниваем ее к нулю:\n",
        "\n",
        "$$\n",
        "\\dfrac{d \\ln(L(\\lambda | data))}{d \\lambda} = -n + \\sum x_i \\cdot \\dfrac{1}{\\lambda}\n",
        "$$\n",
        "\n",
        "Приравниваем к 0:\n",
        "\n",
        "$$\n",
        "\\dfrac{d \\ln(L(\\lambda | data))}{d \\lambda} = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Rightarrow -n + \\sum x_i \\cdot \\dfrac{1}{\\lambda} = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow \\hat{\\lambda}^{MLE} = \\dfrac{\\sum x_i}{n} = \\bar{x}\n",
        "$$\n",
        "\n",
        "Пришли к логичному выводу, что MLE оценка параметра $ \\lambda $ для распределения Пуассона равна среднему арифметическому числа событий.\n",
        "\n",
        "Теперь мы можем легко найти ответ:\n",
        "\n",
        "$$\n",
        "\\hat{\\lambda}^{MLE} = \\bar{x} = \\dfrac{2 + 3 + 2 + 4 + 1 + 3 + 3 + 2 + 4 + 5 + 1 + 2}{12} = 2.(6)\n",
        "$$\n",
        "\n",
        "Значит оценка среднего числа избирателей, которое приходит на участок за 1 час примерно равно $2.67$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeOG15dQKsU4"
      },
      "source": [
        "$$\n",
        "L(\\lambda | data) = ... \\cdot \\dfrac{\\lambda^x}{x!} e^{- \\lambda} \\cdot ... = e^{-n \\lambda} \\cdot \\lambda ^{\\sum x_i} \\cdot \\dfrac{1}{\\prod_{i=1}^{n} x_i !}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLeUVSW_KsU4"
      },
      "source": [
        "Проанализируем, откуда мы взяли эти три множителя:\n",
        "1. $ e^{-n \\lambda} $: множитель $ \\ e^{- \\lambda}$ повторяется $n$ раз по числу элементов в выборке, поскольку $\\lambda$ — постоянная величина, а при умножении степени складываются.\n",
        "    * Например, $ e^{- \\lambda} \\cdot e^{- \\lambda} \\cdot e^{- \\lambda} = e^{- 3\\lambda}$\n",
        "2. $ \\lambda ^{\\sum x_i} $: множитель в виде числителя из дроби $ \\dfrac{\\lambda^x}{x!} $ также повторяется $n$ раз, однако каждый раз на месте $ \\lambda^x $ будет $\\lambda^{i\\text{-й элемент выборки}}$. Следовательно, поскольку $\\lambda$ — постоянная величина, можем просуммировать элементы нашей выборки.\n",
        "    * Например, для выборки $\\{3, 5, 7 \\}$ получим $ \\lambda^3 \\cdot \\lambda^5 \\cdot \\lambda^7 = \\lambda^{15} $\n",
        "3. $ \\dfrac{1}{\\prod_{i=1}^{n} x_i !} $: все просто — каждый раз подставляем в знаменатель из дроби $ \\dfrac{\\lambda^x}{x!} $ новый элемент выборки $x_i$, в результате получаем произведение из факториалов всех элементов нашей выборки (напомним, что символ $\\prod_{i=1}^{n}$ означает произведение элементов по аналогии с символом суммирования $\\sum_{i=1}^{n}$).\n",
        "    * Например, для выборки $\\{1, 2, 3 \\}$ получим $ 1! \\cdot 2! \\cdot 3! = 1 \\cdot 2 \\cdot 6 = 6$\n",
        "        * Напомним, что факториал числа $x!$ равен $ x \\cdot (x - 1) \\cdot ... \\cdot 1 $ или $ \\prod_{k=1}^{x} k $  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzKKrdErKsU4"
      },
      "source": [
        "#### Решение в Python\n",
        "\n",
        "Как и раньше, попробуем «вручную» оптимизировать функцию правдоподобия для решения этой задачи. Воспользуемся уже знакомым синтаксисом и функцией `minimize_scalar`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUmAqj9vKsU5",
        "outputId": "89b36b16-aec6-479e-9ade-74a3b872826e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Выборка: [2, 3, 2, 4, 1, 3, 3, 2, 4, 5, 1, 2]\n",
            "MLE-оценка для параметра lambda: 2.6666681102332452 (с логарифмированием функции правдоподобия)\n"
          ]
        }
      ],
      "source": [
        "# документация: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import poisson\n",
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "# Выборка\n",
        "rally_counts = [2, 3, 2, 4, 1, 3, 3, 2, 4, 5, 1, 2]\n",
        "\n",
        "# Функция логарифмического правдоподобия для распределения Пуассона\n",
        "def log_likelihood(lambda_param):\n",
        "    # logpmf: logarithm of the probability mass function\n",
        "    return np.sum(poisson.logpmf(rally_counts, lambda_param))\n",
        "\n",
        "# Нахождение lambda, которая максимизирует логарифмическое правдоподобие\n",
        "result = minimize_scalar(lambda lambda_param: -log_likelihood(lambda_param), bounds=(0, 10), method='bounded')\n",
        "\n",
        "# MLE для lambda\n",
        "mle_lambda = result.x\n",
        "\n",
        "print(f'Выборка: {rally_counts}')\n",
        "print(f'MLE-оценка для параметра lambda: {mle_lambda} (с логарифмированием функции правдоподобия)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPa2i8DaKsU6"
      },
      "source": [
        "Получили очень точный результат!\n",
        "\n",
        "Обратите внимание, что мы использовали функцию `poisson.logpmf` из библиотеки `scipy`, которая, в отличие от обычной обычной `pmf`, сразу возвращает логарифмированный результат, удобный для нас. Можете сами попробовать изменить `poisson.logpmf` на `poisson.pmf`, а `np.sum` на `np.prod` и сравнить результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxwljDN_KsU7"
      },
      "source": [
        "### 4. Пример MLE для экспоненциального распределения <a name=\"par4\"></a>\n",
        "\n",
        "#### Вспоминаем экспоненциальное распределение\n",
        "\n",
        "Вспомним основные характеристики экспоненциального распределения.\n",
        "\n",
        "Экспоненциальное распределение — непрерывное распределение вероятности, моделирующее время между двумя последовательными свершениями одного и того же события.\n",
        "\n",
        "В отличие от *дискретных* распределений, которые используются для счетных событий (например, распределение Пуассона), *непрерывное* распределение, подобное экспоненциальному, используется для исследования непрерывных величин, например, временных интервалов.\n",
        "\n",
        "Как обсуждалось ранее, **экспоненциальное распределение** широко используется в социальных и естественных науках для моделирования времени до наступления события.\n",
        "\n",
        "**Функция плотности** экспоненциального распределения для произвольной величины выглядит следующим образом:\n",
        "$$\n",
        "\\lambda e^{-\\lambda x},\n",
        "$$\n",
        "где\n",
        "$\\lambda = \\dfrac{1}{\\theta} $ и $\\lambda > 0$ — параметр «интенсивности» события или частота, а $\\theta$ — средняя продолжительность; при этом $ x \\geq 0 $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrNLxaCUKsU8"
      },
      "source": [
        "#### Нахождение оценки MLE для экспоненциального распределения\n",
        "\n",
        "Разовьем идею из задачи для распределения Пуассона, которую мы решали ранее — тогда мы анализировали частоту явки избирателей на парламентских выборах в городе N.\n",
        "\n",
        "Посмотрим на продолжительность времени, которое избиратели проводят в кабинке для голосования, принимая свое решение (и, возможно, зайдем в область политической психологии). Это классический сценарий для применения экспоненциального распределения, поскольку он включает оценку средней продолжительности непрерывного процесса (времени, проведенного избирателями в кабинке).\n",
        "\n",
        "Найдем оценку среднего времени, которое избиратель проводит в кабинке для голосования, с помощью MLE.\n",
        "\n",
        "Предположим, что наблюдения проводились на том же избирательном участке. Записывалось время (в минутах), которое каждый избиратель проводил в кабинке для голосования. Мы имеем следующую выборку из 10 человек:\n",
        "$$\n",
        "X = \\{3, 5, 2, 4, 3, 5, 4, 6, 2, 5\\}\n",
        "$$\n",
        "\n",
        "В начале выведем оценку $\\theta$, т.е. средней продолжительности, в общем виде:\n",
        "\n",
        "**Функция правдоподобия**\n",
        "$$\n",
        "L(\\theta | data) = ... \\cdot \\dfrac{1}{\\theta} \\cdot e^{- \\frac{x}{\\theta} } \\cdot ... = \\left( \\dfrac{1}{\\theta} \\right)^n \\cdot e^{- \\frac{1}{\\theta} \\cdot \\left( \\sum x_i \\right) }\n",
        "$$\n",
        "**Логарифмическая функция правдоподобия**\n",
        "$$\n",
        "\\ln(L(\\theta | data)) = -n \\ln(\\theta) - \\dfrac{1}{\\theta} \\cdot \\sum x_i\n",
        "$$\n",
        "**Дифференцирование и максимизация**\n",
        "$$\n",
        "\\dfrac{d \\ln(L(\\theta | data))}{d \\theta} = - \\dfrac{n}{\\theta} - \\sum x_i \\cdot \\cdot \\left( - \\dfrac{1}{\\theta^2} \\right)\n",
        "$$\n",
        "$$\n",
        "\\dfrac{d \\ln(L(\\theta | data))}{d \\theta} = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow - \\dfrac{n}{\\theta} - \\sum x_i \\cdot \\left( - \\dfrac{1}{\\theta^2} \\right) = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow \\hat{\\theta}^{MLE} = \\dfrac{\\sum x_i}{n} = \\bar{x}\n",
        "$$\n",
        "\n",
        "Теперь мы можем легко найти ответ на задачу:\n",
        "\n",
        "$$\n",
        "\\hat{\\theta}^{MLE} = \\bar{x} = \\dfrac{3 + 5 + 2 + 4 + 3 + 5 + 4 + 6 + 2 + 5}{10} = 3.9\n",
        "$$\n",
        "\n",
        "Выходит, что, согласно нашим данным, в среднем, избиратель проводит $3.9$ минут в избирательной кабинке на выборах в городе N."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k87hgWDzKsU8"
      },
      "source": [
        "**Усложним условие**: пускай в функции правдоподобия будут участвовать как функции распределения, так и функции надежности. Например, скажем, что мы точно знаем время для 6 избирателей: 3, 2, 4, 3, 4, 2, а для четырех — время голосования составило 5 минут и более (раньше мы считали, что трое из этих избирателей сделали свой выбор за 5 минут, а один — за 6).\n",
        "\n",
        "Тогда наша выборка будет выглядеть следующим образом:\n",
        "|    t     |     n    |\n",
        "|----------|----------|\n",
        "| 2 min    |      2         |\n",
        "| 3 min    |      2         |\n",
        "| 4 min    |      2         |\n",
        "| [5 min; $+ \\infty$) | 4   |\n",
        "\n",
        "В такой ситуации расчет функции правдоподобия немного изменится: мы будем комбинировать функции распределения и функции надежности, которые мы уже обсуждали подробно в контексте экспоненциального распределения. Посчитаем MLE-оценку вручную:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNsr7trHKsU9"
      },
      "source": [
        "\n",
        "**Функция правдоподобия**\n",
        "$$\n",
        "L(\\theta | data) =  \\left( \\dfrac{1}{\\theta} \\cdot e^{- \\frac{2}{\\theta}} \\right)^2 \\cdot \\left( \\dfrac{1}{\\theta} \\cdot e^{- \\frac{3}{\\theta}} \\right)^2 \\cdot\n",
        "\\left( \\dfrac{1}{\\theta} \\cdot e^{- \\frac{4}{\\theta}} \\right)^2 \\cdot \\left( e^{- \\frac{5}{\\theta}} \\right)^4 = \\left( \\dfrac{1}{\\theta}  \\right)^6 \\cdot\n",
        "e^{- \\frac{38}{\\theta}}\n",
        "$$\n",
        "**Логарифмическая функция правдоподобия**\n",
        "$$\n",
        "\\ln(L(\\theta | data)) = - 6 \\ln(\\theta) - \\dfrac{38}{\\theta}\n",
        "$$\n",
        "**Дифференцирование и максимизация**\n",
        "$$\n",
        "\\dfrac{d \\ln(L(\\theta | data))}{d \\theta} = - \\dfrac{6}{\\theta} + \\dfrac{38}{\\theta^2}\n",
        "$$\n",
        "$$\n",
        "- \\dfrac{6}{\\theta} + \\dfrac{38}{\\theta^2} = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow \\dfrac{6}{\\theta} = \\dfrac{38}{\\theta^2}\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow \\hat{\\theta}^{MLE} = \\dfrac{38}{6} = 6.(3)\n",
        "$$\n",
        "\n",
        "Получили, что с измененным условием, когда наблюдения $5, 5, 5, 6$ «превратились» в четыре $5+$, оценка математического ожидания среднего времени голосования увеличилась с $3.9$ до $6.(3)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeInhDUfKsU9"
      },
      "source": [
        "#### Решение в Python\n",
        "\n",
        "Попробуем решить обе версии задачи с помощью Python: как только с функциями распределения, так и дополнительно с функциями надежности.\n",
        "\n",
        "Для расчета логарифмической функции правдоподобия будем использовать две функции из `scipy.stats`:\n",
        "- `expon.logpdf`: log of the probability density function\n",
        "- `expon.logsf`: log of the survival function\n",
        "\n",
        "В начале решим первую вариацию задания:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oSBQDMWKsU9",
        "outputId": "b34b6bda-d365-4fd5-b771-1e4575f03802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Выборка: [3, 5, 2, 4, 3, 5, 4, 6, 2, 5]\n",
            "MLE-оценка для параметра theta: 3.900013550547837 (с логарифмированием функции правдоподобия)\n"
          ]
        }
      ],
      "source": [
        "# Документация: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import expon\n",
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "# Выборка\n",
        "voting_time = [3, 5, 2, 4, 3, 5, 4, 6, 2, 5]\n",
        "\n",
        "# Функция логарифмического правдоподобия для экспоненциального распределения\n",
        "def exp_log_likelihood(lambda_param):\n",
        "    # Технически удобнее оптимизировать lambda, а потом выразить из нее theta\n",
        "    pdf_contrib = np.sum(expon.logpdf(voting_time, scale=1/lambda_param))\n",
        "\n",
        "    return pdf_contrib\n",
        "\n",
        "# Нахождение lambda, которая максимизирует логарифмическое правдоподобие\n",
        "result = minimize_scalar(lambda x: -exp_log_likelihood(x), bounds=(0, 1), method='bounded')\n",
        "\n",
        "# MLE для lambda\n",
        "mle_lambda = result.x\n",
        "\n",
        "print(f'Выборка: {voting_time}')\n",
        "print(f'MLE-оценка для параметра theta: {1 / mle_lambda} (с логарифмированием функции правдоподобия)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs0jUSLwKsU-"
      },
      "source": [
        "Теперь решим усложненный вариант задания. Поскольку мы используем логарифм правдоподобия, можем по отдельности найти значения функций распределения и функций надежности, а затем сложить их:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtYvazkGKsU-",
        "outputId": "a0caadbd-4098-4fc8-cdaa-ffae09317b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Выборка: 3, 2, 4, 3, 4, 2, 5+, 5+, 5+, 5+\n",
            "MLE-оценка для параметра theta: 6.333278679750698 (с логарифмированием функции правдоподобия)\n"
          ]
        }
      ],
      "source": [
        "# Выборка\n",
        "voting_time = [3, 2, 4, 3, 4, 2]  # остальные значения передадим напрямую\n",
        "\n",
        "# Функция логарифмического правдоподобия для экспоненциального распределения\n",
        "def extended_exp_log_likelihood(lambda_param):\n",
        "    # Технически удобнее оптимизировать lambda, а потом выразить из нее theta\n",
        "    pdf_contrib = np.sum(expon.logpdf(voting_time, scale=1/lambda_param))\n",
        "\n",
        "    # Считаем логарифм функции надежности\n",
        "    survival_contrib = np.sum(expon.logsf([5] * 4, scale=1/lambda_param))\n",
        "\n",
        "    return pdf_contrib + survival_contrib\n",
        "\n",
        "# Нахождение lambda, которая максимизирует логарифмическое правдоподобие\n",
        "result = minimize_scalar(lambda x: -extended_exp_log_likelihood(x), bounds=(0, 1), method='bounded')\n",
        "\n",
        "# MLE для lambda\n",
        "mle_lambda = result.x\n",
        "\n",
        "print(f\"Выборка: {', '.join(list(map(str, voting_time)) + ['5+', '5+', '5+', '5+'])}\")\n",
        "print(f'MLE-оценка для параметра theta: {1 / mle_lambda} (с логарифмированием функции правдоподобия)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb_o7C4BKsU-"
      },
      "source": [
        "Оба раза получили правильный ответ!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11pSwrlqKsU_"
      },
      "source": [
        "### 5. Пример MLE для нормального распределения <a name=\"par5\"></a>\n",
        "\n",
        "#### Вспоминаем нормальное распределение\n",
        "\n",
        "Как мы помним, нормальное распределение очень важно для теории вероятностей, оно широко используется в различных прикладных областях и в самой теории вероятностей и математической статистике.\n",
        "\n",
        "В политической науке нормальное распределение может использоваться для анализа поведения избирателей, опросов общественного мнения, экономических показателей, и многого другого. Также оно часто используется при проверке гипотез и оценке доверительных интервалов, а также в качестве основы для более сложных статистических моделей.\n",
        "\n",
        "#### Функция плотности вероятности\n",
        "\n",
        "Функция плотности вероятности нормального распределения задается формулой:\n",
        "\n",
        "$$\n",
        "f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
        "$$,\n",
        "где $ \\sigma $ — стандартное отклонение, и $ \\mu $ — среднее значение распределения.\n",
        "\n",
        "Рассмотрим стандартное нормальное распределение и будем в дальнейшем работать с ним для простоты.\n",
        "Напомним, что у стандартного нормального распределения $ \\sigma = 1 $ и $ \\mu = 0$.\n",
        "\n",
        "#### Нахождение оценки MLE для нормального распределения (для среднего значения)\n",
        "\n",
        "Попробуем вывести оценку параметра $\\mu $ и решить следующую задачу:\n",
        "\n",
        "##### Задача\n",
        "\n",
        "Представим, что социологическое агентство обратилось к нам с просьбой проанализировать опрос общественного мнения о поддержке кандидата N.\n",
        "Мы знаем, что выборка пришла к нам из нормального распределения со стандартным отклонением, равным 1.\n",
        "\n",
        "Мы имеем следующую выборку (шкала от 1 до 10, где 1 означает решительное несогласие, а 10 — решительную поддержку):\n",
        "$$\n",
        "X = \\{6, 8, 7, 5, 9, 7, 6, 8, 5, 7\\}\n",
        "$$\n",
        "\n",
        "Нам необходимо найти оценку среднего значения поддержки политика N с помощью MLE.\n",
        "\n",
        "##### Решение\n",
        "\n",
        "**Функция правдоподобия**: воспользуемся тем, что $ \\sigma = 1 $\n",
        "$$\n",
        "L(\\mu | data) = ... \\cdot  \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2}} \\cdot ... = \\left( \\dfrac{1}{\\sqrt{2\\pi}} \\right)^n \\cdot e^{- \\frac{1}{2} \\sum_{i=1}^n (x_i - \\mu)^2}\n",
        "$$\n",
        "**Логарифмическая функция правдоподобия**\n",
        "$$\n",
        "\\ln(L(\\mu | data)) = \\ln\\left( \\left( \\dfrac{1}{\\sqrt{2\\pi}} \\right)^n \\right) - \\frac{1}{2} \\sum_{i=1}^n (x_i - \\mu)^2\n",
        "$$\n",
        "\n",
        "Как можно понять, $ \\ln\\left( \\left( \\dfrac{1}{\\sqrt{2\\pi}} \\right)^n \\right) $ будет являться для нас константой при дифференцировании.\n",
        "\n",
        "**Дифференцирование и максимизация**\n",
        "$$\n",
        "\\dfrac{d \\ln(L(\\mu | data))}{d \\mu} = - \\frac{1}{2} \\sum_{i=1}^n (- 2 (x_i - \\mu) )\n",
        "$$\n",
        "$$\n",
        "- \\frac{1}{2} \\sum_{i=1}^n (- 2 (x_i - \\mu) ) = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow \\sum_{i=1}^n (x_i - \\mu) = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow \\sum_{i=1}^n x_i - n \\mu = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow \\hat{\\mu}^{MLE} = \\dfrac{\\sum_{i=1}^n x_i }{n} = \\bar{x}\n",
        "$$\n",
        "\n",
        "Мы получили, что MLE-оценкой параметра $ \\mu $ нормального распределения (при условии $ \\sigma = 1 $) является выборочное среднее! На самом деле, если опустить условие $ \\sigma = 1 $, результат будет такой же, но вывод несколько усложнится."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etggl6lBKsU_"
      },
      "source": [
        "\n",
        "\n",
        "Стоит отметить *свойства* этой оценки:\n",
        "- **несмещенная**: математическое ожидание оценки равно оцениваемому параметру или $E(\\hat{\\theta}) = \\theta$\n",
        "- **состоятельная**: сходится по вероятности к истинному значению параметра по мере увеличения размера выборки (с увеличением объема выборки оценка становится более точной)\n",
        "или, если для любого $ \\epsilon > 0: \\ \\lim_{n \\to \\infty} P(|\\hat{\\theta}_n - \\theta| < \\epsilon) = 1 $\n",
        "- **эффективная**: среди всех несмещенных оценок, эффективная оценка имеет наименьшую дисперсию (оценка использует выборочные данные наиболее эффективно) или\n",
        "между двумя несмещенными оценками $ \\hat{\\theta}_1 $ и $ \\hat{\\theta}_2 $, $ \\hat{\\theta}_1 $ более эффективна, чем $ \\hat{\\theta}_2 $, если $Var(\\hat{\\theta}_1) < Var(\\hat{\\theta}_2) $\n",
        "- **НЕустойчивая**: чувствительна к выбросам в данных (в отличие от медианы, например)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-rKgqkuKsVA"
      },
      "source": [
        "Теперь мы можем легко решить задачу!\n",
        "\n",
        "$$\n",
        "\\hat{\\mu}^{MLE} = \\bar{x} = \\dfrac{6 + 8 + 7 + 5 + 9 + 7 + 6 + 8 + 5 + 7}{10} = 6.8\n",
        "$$\n",
        "\n",
        "Получается, что MLE-оценка среднего значения поддержки кандидата N равна $ 6.8 $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2jahO1FKsVA"
      },
      "source": [
        "#### Решение в Python\n",
        "\n",
        "Для расчета логарифмической функции правдоподобия будем использовать функцию из `scipy.stats`: `norm.logpdf` (log of the probability density function)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yeuPvVUKsVA",
        "outputId": "fe2c196d-8564-4c16-9e4e-d10f299229d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Выборка: [6, 8, 7, 5, 9, 7, 6, 8, 5, 7]\n",
            "MLE-оценка для параметра mu: 6.80000000000001 (с логарифмированием функции правдоподобия)\n"
          ]
        }
      ],
      "source": [
        "# Документация: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "# Выборка\n",
        "opinion_ratings = [6, 8, 7, 5, 9, 7, 6, 8, 5, 7]\n",
        "\n",
        "# Функция логарифмического правдоподобия для экспоненциального распределения\n",
        "def normal_log_likelihood(mu):\n",
        "    # Берем с минусом, потому что будем минимизировать\n",
        "    return -np.sum(norm.logpdf(opinion_ratings, loc=mu, scale=1))  # предположение: sigma = 1\n",
        "\n",
        "# Нахождение mu, которая максимизирует логарифмическое правдоподобие\n",
        "normal_result = minimize_scalar(normal_log_likelihood)\n",
        "\n",
        "# MLE для mu\n",
        "mle_mu = normal_result.x\n",
        "\n",
        "print(f\"Выборка: {opinion_ratings}\")\n",
        "print(f'MLE-оценка для параметра mu: {mle_mu} (с логарифмированием функции правдоподобия)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-oJoW0EKsVB"
      },
      "source": [
        "Получили правильный результат!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tvims_2_workspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}